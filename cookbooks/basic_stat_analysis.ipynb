{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3242c62",
   "metadata": {},
   "source": [
    "# Statistical Analysis on trial results\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Goal of this cookbook is to illustrate how one can query trial results and run a statistical analysis on it. We'll use Logistic Regression example\n",
    "\n",
    "Linked resources: \n",
    "- [Folder on jinko](https://jinko.ai/project/e0fbb5bb-8929-439a-bad6-9e12d19d9ae4?labels=98d0ccc1-5c91-4697-886a-bec1cdf8c899)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d232f9cb-d8c3-42c5-839e-18299ac270b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Jinko specifics imports & initialization\n",
    "# Please fold this section and do not change\n",
    "import jinko_helpers as jinko\n",
    "\n",
    "# Connect to Jinko (see README.md for more options)\n",
    "jinko.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087cd001-eb69-4f91-a7f8-5a4af8229589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cookbook specifics imports\n",
    "\n",
    "import io\n",
    "import json\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import zipfile\n",
    "\n",
    "# Cookbook specifics constants:\n",
    "# put here the constants that are specific to your cookbook like\n",
    "# the reference to the Jinko items, the name of the model, etc.\n",
    "\n",
    "# @param {\"name\":\"trialId\", \"type\": \"string\"}\n",
    "# trial short id can be retrieved in the url, pattern is `https://jinko.ai/<trail_sid>`\n",
    "trial_sid = \"tr-HLRF-b0zW\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd32e10a",
   "metadata": {},
   "source": [
    "# Step 1: Load the trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beca2279",
   "metadata": {},
   "source": [
    "### Get the latest completed version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a8d40f-f6d1-4250-8a0d-b1c4e07c8780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert short id to core item id\n",
    "trial_core_item_id = jinko.get_core_item_id(trial_sid, 1)\n",
    "\n",
    "# List all trial versions\n",
    "# https://doc.jinko.ai/api/#/paths/core-v2-trial_manager-trial-trialId--status/get\n",
    "response = jinko.make_request(\n",
    "    f'/core/v2/trial_manager/trial/{trial_core_item_id[\"id\"]}/status'\n",
    ")\n",
    "versions = response.json()\n",
    "\n",
    "# Get the latest completed version\n",
    "try:\n",
    "    latest_completed_version = next(\n",
    "        (item for item in versions if item[\"status\"] == \"completed\"), None\n",
    "    )\n",
    "    if latest_completed_version is None:\n",
    "        raise Exception(\"No completed trial version found\")\n",
    "    else:\n",
    "        print(\n",
    "            \"Successfully fetched this simulation:\\n\",\n",
    "            json.dumps(latest_completed_version, indent=1),\n",
    "        )\n",
    "        simulation_id = latest_completed_version[\"simulationId\"]\n",
    "        trial_core_item_id = simulation_id[\"coreItemId\"]\n",
    "        trial_snapshot_id = simulation_id[\"snapshotId\"]\n",
    "except Exception as e:\n",
    "    print(f\"Error processing trial versions: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b13c12",
   "metadata": {},
   "source": [
    "# Step 2 : Get and post process the trial results and p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5eaa7f2",
   "metadata": {},
   "source": [
    "### Display a summary of simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfcfb73-d8d4-418d-89af-1f65b05e23a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_summary = jinko.get_trial_scalars_summary(\n",
    "    trial_core_item_id, trial_snapshot_id, print_summary=True\n",
    ")\n",
    "\n",
    "# Store the list of scenario descriptors fetch them\n",
    "scenario_descriptors = [\n",
    "    scalar[\"id\"]\n",
    "    for scalar in (response_summary[\"scalars\"] + response_summary[\"categoricals\"])\n",
    "    if \"ScenarioOverride\" in scalar[\"type\"][\"labels\"]\n",
    "]\n",
    "print(\"List of scenario overrides:\\n\", scenario_descriptors, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31a4ddf",
   "metadata": {},
   "source": [
    "### Retrieve scalar results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429b60f7-e004-40a5-867e-bdacfb8d4f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_scalars = jinko.get_trial_scalars_as_dataframe(\n",
    "    trial_core_item_id,\n",
    "    trial_snapshot_id,\n",
    "    scalar_ids=[\n",
    "        \"Blood.Drug.max\",\n",
    "        \"initialTumorBurden.tmin\",\n",
    "        \"bloodFlowRate.tmin\",\n",
    "        \"initialCountCancerCells.tmin\",\n",
    "        \"lymphDrainingRate.tmin\",\n",
    "        \"vmaxCancerCellDeath.tmin\",\n",
    "        \"tumorBurdenChangeFromBaseline.tend\",\n",
    "        \"lymphaticFlowRate.tmin\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b205c197-3d19-4eb9-83c3-eb20d35f7ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Raw scalar data (first rows):\\n\")\n",
    "display(df_scalars.head())\n",
    "print(\"\\nNumber of patients in the original table:\", len(df_scalars))\n",
    "\n",
    "# Filter patients (keeping only cross arm baseline values and IV 10mg dose)\n",
    "df_scalars = df_scalars[df_scalars[\"armId\"].isin([\"crossArms\", \"iv-1-10\"])]\n",
    "print(f\"\\nNumber of patients in the table after filtering:\", len(df_scalars))\n",
    "\n",
    "# Pivot to a wide format\n",
    "df_scalars = df_scalars.drop(\"armId\", axis=1)\n",
    "df_scalars = df_scalars.pivot(index=\"patientId\", columns=\"scalarId\", values=\"value\")\n",
    "\n",
    "# Check the result\n",
    "print(\"\\nPivoted scalar table (first rows):\")\n",
    "display(df_scalars.head())\n",
    "\n",
    "# Create a column for the response to the treatment\n",
    "df_scalars[\"responder\"] = df_scalars[\"tumorBurdenChangeFromBaseline.tend\"].apply(\n",
    "    lambda x: x <= -95\n",
    ")\n",
    "print(\"\\nResponse variable (first rows):\")\n",
    "display(df_scalars[[\"tumorBurdenChangeFromBaseline.tend\", \"responder\"]].head())\n",
    "\n",
    "# Check if there are NaN values in the table\n",
    "nan_rows = df_scalars.isna().any(axis=1)\n",
    "id_to_remove = nan_rows[nan_rows].index.values\n",
    "print(\n",
    "    \"\\n\",\n",
    "    len(id_to_remove),\n",
    "    \"patient(s) containing NaN values in the table will be removed:\",\n",
    ")\n",
    "display(df_scalars[df_scalars.index.isin(id_to_remove)])\n",
    "\n",
    "# Remove corresponding row(s)\n",
    "df_scalars = df_scalars.drop(index=id_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23849cc",
   "metadata": {},
   "source": [
    "# Step 3 : Logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c8606e-19aa-4d9b-a261-b412974c034f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "featureCols = [\n",
    "    \"Blood.Drug.max\",\n",
    "    \"initialTumorBurden.tmin\",\n",
    "    \"bloodFlowRate.tmin\",\n",
    "    \"initialCountCancerCells.tmin\",\n",
    "    \"lymphDrainingRate.tmin\",\n",
    "    \"vmaxCancerCellDeath.tmin\",\n",
    "    \"lymphaticFlowRate.tmin\",\n",
    "]\n",
    "\n",
    "X = df_scalars[featureCols]  # Features\n",
    "y = df_scalars.responder  # Target variable\n",
    "\n",
    "# Print the number of samples in each class\n",
    "counts = df_scalars[\"responder\"].value_counts()\n",
    "print(\"Number of samples in each class:\")\n",
    "for label, count in counts.items():\n",
    "    print(f\"{label}: {count}\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=16\n",
    ")\n",
    "\n",
    "# Create a pipeline that fits a logistic regression model\n",
    "model = make_pipeline(LogisticRegression(random_state=16))\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix and classification report\n",
    "confusion_matrix_result = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(confusion_matrix_result)\n",
    "print(\"\\nClassification report:\")\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test, y_pred, target_names=[\"Non-responder\", \"Responder\"], zero_division=0\n",
    "    )\n",
    ")\n",
    "\n",
    "# Produce a ROC curve\n",
    "y_pred_prob = model.predict_proba(X_test)[::, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=fpr, y=tpr, mode=\"lines\", name=f\"data 1, auc = {auc:.3f}\"))\n",
    "fig.update_layout(\n",
    "    title=\"ROC Curve\",\n",
    "    xaxis_title=\"False Positive Rate\",\n",
    "    yaxis_title=\"True Positive Rate\",\n",
    "    xaxis=dict(range=[0, 1]),\n",
    "    yaxis=dict(range=[0, 1]),\n",
    "    margin=dict(b=50, t=50, l=50, r=50),\n",
    "    width=500,\n",
    "    height=500,\n",
    ")\n",
    "fig.add_annotation(\n",
    "    text=f\"AUC = {auc:.3f}\",\n",
    "    x=1,\n",
    "    y=0,\n",
    "    xref=\"paper\",\n",
    "    yref=\"paper\",\n",
    "    showarrow=False,\n",
    "    font=dict(size=14),\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
