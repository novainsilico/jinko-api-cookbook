{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of resolution of a Non Linear Mixed Effect Model\n",
    "In this example, we have a ODE with several parameters, and we used First Order Conditional Estimation (FOCE) method to find the parameters values.\n",
    "\n",
    "The individual datas are artificially generated using the actual parameter values and by adding some variability and noise. \n",
    "\n",
    "In NonMem, parameters for the i-th individual are written with the following form:\n",
    "\n",
    "$$K_i = K_{pop} e^{\\eta_i}, \\eta_i \\sim \\ N(0,\\omega_{pop})$$\n",
    "\n",
    "where $K_{pop}$ and $\\omega_{pop}$ are population specific. \n",
    "\n",
    "\n",
    "The goal of this cookbook is to find the following values:\n",
    "- At the population level: $K_{pop}$ and $\\omega_{pop}$\n",
    "- At the individual level: $\\eta_i$\n",
    "\n",
    "And checks that the $\\eta_i \\sim \\ N(0,\\omega_{pop})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from scipy.integrate import solve_ivp\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem definitions\n",
    "\n",
    "### Definition of the ODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ODE function\n",
    "def ode_model(t, C, K):\n",
    "    return - K * C\n",
    "\n",
    "y0 = [100]  # Initial ODE condition\n",
    "\n",
    "outputName = \"Concentration\"\n",
    "\n",
    "# Define the population level parameters\n",
    "K_pop = 3  # Typical elimination rate constant\n",
    "Var_pop = 0.5  # Between-subject variability (log-normal)\n",
    "sigma_noise = 0.2  # Residual error\n",
    "\n",
    "\n",
    "# Define the initial conditions for the optmization algorithm (close the aimed value)\n",
    "K_pop_init = 5 # population-level parameter\n",
    "Var_pop_init = 1  # Random effect\n",
    "# Combine them into one initial parameter vector\n",
    "initial_params = np.hstack([K_pop_init, Var_pop_init])\n",
    "bounds = [(0.01, None)] * len(initial_params)  # to avoid unrealistic values of K that can make the model go crazy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data for 5 individuals, and 10 observations\n",
    "np.random.seed(43)\n",
    "n_individuals = 5\n",
    "n_obs = 10\n",
    "t_max = 4\n",
    "time_points = np.linspace(0, t_max, n_obs)  # 10 time points from 0 to 10\n",
    "\n",
    "# Simulated dataset\n",
    "data = []\n",
    "\n",
    "for i in range(n_individuals):\n",
    "    eta_pop = np.random.normal(0, Var_pop)  # Random effect\n",
    "    Kel_i = np.multiply(K_pop, np.exp(eta_pop))  # Individual parameters\n",
    "\n",
    "    # Solve the ODE\n",
    "    sol = solve_ivp(ode_model, [0, max(time_points)], y0, t_eval=time_points, args=(Kel_i,))\n",
    "    # Add measurement noise\n",
    "    noise = np.random.normal(0, sigma_noise, size=n_obs)\n",
    "    C_obs = sol.y[0] + noise\n",
    "\n",
    "    # Store data\n",
    "    for t, C in zip(time_points, C_obs):\n",
    "        data.append([i, t, C])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"Individual\", \"Time\", outputName])\n",
    "\n",
    "# Select the first 3 patients at most to check\n",
    "individual_ids = df['Individual'].unique()[:min(3, n_individuals )]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for individual_id in individual_ids:\n",
    "    individual_data = df[df['Individual'] == individual_id]\n",
    "    plt.plot(individual_data['Time'], individual_data[outputName], label=f'Individual {individual_id}', marker='o')\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel(outputName)\n",
    "plt.title(f'Evolution of {outputName} for each Individual')\n",
    "plt.legend(title='Individuals')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization functions definitions\n",
    "We defined the FOCE likelihood function (and a tool function for readibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to simulate concentration given K\n",
    "def simulate_model(K, y0, time_points):\n",
    "    sol = solve_ivp(ode_model, [0, max(time_points)], y0, t_eval=time_points, args=(K,))\n",
    "    return sol.y[0]\n",
    "\n",
    "def obj_fun_eta_star(eta_i, parameters, C_obs, time_points, sigma_noise):\n",
    "    theta = parameters[0]\n",
    "    omega = parameters[1]\n",
    "\n",
    "    K_i = theta * np.exp(eta_i)\n",
    "\n",
    "    C_pred       = simulate_model(K_i, y0, time_points)\n",
    "    residuals = C_obs - C_pred\n",
    "\n",
    "    return np.sum( residuals**2 / (2 * sigma_noise**2)) + eta_i**2 / (2 * omega**2)\n",
    "\n",
    "\n",
    "\n",
    "# FOCE likelihood function\n",
    "def foce_minus_log_likelihood(params, df, n_individuals, time_points, sigma_noise):\n",
    "    theta = params[0]  # Population parameter\n",
    "    omega = params[1]  # Variability \n",
    "\n",
    "    log_likelihood = 0\n",
    "    for i in range(n_individuals):\n",
    "        # Extract observed data for this individual\n",
    "        C_obs = df[df[\"Individual\"] == i][outputName].values\n",
    "\n",
    "        # Find eta_i_star\n",
    "        eta_i=0\n",
    "        opt_result = minimize(obj_fun_eta_star, eta_i, args=(params, C_obs, time_points, sigma_noise))\n",
    "        eta_i_star = opt_result.x[0]\n",
    "\n",
    "        # Establish individual parameter value\n",
    "        K_i = theta * np.exp(eta_i_star)\n",
    "        # Predicted values for C, C' and C''\n",
    "        C_pred       = simulate_model(K_i, y0, time_points)\n",
    "        C_dt_pred    = ode_model(t, C_pred, K_i)\n",
    "        C_dt_dt_pred = ode_model(t, C_dt_pred, K_i)\n",
    "\n",
    "        # Compute residuals and intermediate outputs\n",
    "        #print(C_pred)\n",
    "        residuals = C_obs - C_pred\n",
    "        derivative_squared = C_dt_pred**2\n",
    "        taylor_expansion = residuals * C_dt_dt_pred \n",
    "\n",
    "        # Compute likelihood \n",
    "        ## Compute likelihood of the main part at the individual level\n",
    "        a = np.sum((residuals / sigma_noise) ** 2 + np.log(2 * np.pi * sigma_noise**2))\n",
    "\n",
    "        ## Compute likelihood of the population level\n",
    "        b = np.log(2 * np.pi * omega) + (eta_i/omega)**2\n",
    "\n",
    "        ## Compute likelihood of the taylor expansion part at the individual level\n",
    "        c = - np.log(2 * np.pi) + np.log(abs(-1/(omega**2) + np.sum( (- derivative_squared + taylor_expansion )/(sigma_noise**2))))\n",
    "\n",
    "        \n",
    "        log_likelihood += a + b + c\n",
    "\n",
    "    print(f\"For theta = {theta:.2e} and omega = {omega:.2e}, We have L = {log_likelihood:.3e}\")\n",
    "    return (- log_likelihood)  # Minimize negative log-likelihood\n",
    "\n",
    "\n",
    "log_likelihood = foce_minus_log_likelihood([5.675439391580754,0.26258449412761864], df, n_individuals, time_points, sigma_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization algorithm and visualization of the results\n",
    "\n",
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine them into one initial parameter vector\n",
    "initial_params = np.hstack([K_pop_init, Var_pop_init])\n",
    "bounds = [(0.01, None)] * len(initial_params) \n",
    "\n",
    "# Optimization\n",
    "opt_result = minimize(foce_minus_log_likelihood, initial_params, args=(df, n_individuals, time_points, sigma_noise),\n",
    "                      bounds = bounds, method='Nelder-Mead', options={\"maxiter\":10})  \n",
    "\n",
    "# Extract results\n",
    "K_pop_opt = opt_result.x[0]\n",
    "Var_pop_opt = opt_result.x[1]\n",
    "params_opt = [K_pop_opt, Var_pop_opt]\n",
    "\n",
    "print(f\"Maximum L: {-opt_result.fun:.3e}\")\n",
    "print(f\"Optimized K_pop: {K_pop_opt}\")\n",
    "print(f\"Optimized Var_pop: {Var_pop_opt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results\n",
    "We compare the optimization outputs with the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot observed vs. predicted concentrations\n",
    "#K_pop_opt = 2\n",
    "#Var_pop_opt = 0.5\n",
    "\n",
    "def plot_results(df, theta_kel_opt, time_points):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for i in range(n_individuals):  # Loop over individuals\n",
    "        C_obs = df[df[\"Individual\"] == i][outputName].values\n",
    "\n",
    "        # Find eta_i_star\n",
    "        eta_i=0\n",
    "        opt_result = minimize(obj_fun_eta_star, eta_i, args=(params_opt, C_obs, time_points, sigma_noise))\n",
    "        eta_i_star = opt_result.x[0]\n",
    "        print(f\"i = {i}: exp(eta_i*) = {np.exp(eta_i_star):.2e}\")\n",
    "        Kel_i = theta_kel_opt * np.exp(eta_i_star)  # Individual-specific Kel\n",
    "        C_pred = simulate_model(Kel_i, y0, time_points)  # Model predictions\n",
    "\n",
    "        # Extract observed data for individual i\n",
    "        df_i = df[df[\"Individual\"] == i]\n",
    "\n",
    "        # Scatter plot for observed data\n",
    "        plt.scatter(df_i[\"Time\"], df_i[outputName], label=f\"Observed - ID {i}\")\n",
    "\n",
    "        # Line plot for model-predicted concentrations\n",
    "        plt.plot(time_points, C_pred, linestyle='--', label=f\"Predicted - ID {i} - eta_i={eta_i_star:.2e}\")\n",
    "\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(outputName)\n",
    "    plt.title(\"Observed vs. FOCE Model-Predicted Output\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot results\n",
    "plot_results(df, K_pop_opt, time_points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute residuals and metrics\n",
    "def compute_diagnostics(df, theta_kel_opt, time_points):\n",
    "    residuals = []\n",
    "    all_obs = []\n",
    "    all_pred = []\n",
    "\n",
    "    for i in range(5):\n",
    "        C_obs = df[df[\"Individual\"] == i][outputName].values\n",
    "\n",
    "        # Find eta_i_star\n",
    "        eta_i=0\n",
    "        opt_result = minimize(obj_fun_eta_star, eta_i, args=(params_opt, C_obs, time_points, sigma_noise))\n",
    "        eta_i_star = opt_result.x[0]\n",
    "        Kel_i = theta_kel_opt * np.exp(eta_i_star)\n",
    "        C_pred = simulate_model(Kel_i, y0, time_points)\n",
    "        \n",
    "        residuals.extend(C_obs - C_pred)\n",
    "        all_obs.extend(C_obs)\n",
    "        all_pred.extend(C_pred)\n",
    "\n",
    "    # Compute metrics\n",
    "    mse = mean_squared_error(all_obs, all_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(all_obs, all_pred)\n",
    "\n",
    "    print(f\"MSE (Lower values indicate a better fit) : {mse:.4f}\")\n",
    "    print(f\"RMSE (Lower values indicate a better fit): {rmse:.4f}\")\n",
    "    print(f\"RÂ² (Close to 1 means the model explains most variability): {r2:.4f}\")\n",
    "\n",
    "    return residuals, all_obs, all_pred\n",
    "\n",
    "# Run diagnostics\n",
    "residuals, all_obs, all_pred = compute_diagnostics(df, K_pop_opt, time_points)\n",
    "\n",
    "# Plot Residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(all_obs, residuals, alpha=0.7)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel(\"Observed outputs\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot (Ideally, residuals should be randomly scattered around zero) \")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# QQ-Plot of Residuals\n",
    "import scipy.stats as stats\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title(\"QQ-Plot of Residuals (Helps check if residuals follow a normal distribution)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=2\n",
    "C_pred       = simulate_model(K, y0, time_points)\n",
    "C_dt_pred    = ode_model(t, C_pred, K)\n",
    "C_dt_dt_pred = ode_model(t, C_dt_pred, K)\n",
    "\n",
    "residuals = C_obs - C_pred\n",
    "derivative_squared = C_dt_pred**2\n",
    "taylor_expansion = residuals * C_dt_dt_pred \n",
    "\n",
    "print(residuals)\n",
    "print(derivative_squared)\n",
    "print(taylor_expansion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
