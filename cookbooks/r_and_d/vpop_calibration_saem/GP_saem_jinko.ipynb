{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0190f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import io\n",
    "import jinko_helpers as jinko\n",
    "from IPython.display import display\n",
    "from plotnine import *\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import vpop_calibration\n",
    "\n",
    "# jinko set-up\n",
    "jinko.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484ad334",
   "metadata": {},
   "source": [
    "# Calibrating a population using a QSP model on jinko\n",
    "\n",
    "This notebook demonstrates how to use the [`vpop-calibration`](https://git.novadiscovery.net/jinko/api/vpop-calibration) module to calibrate a QSP model that is simulated on jinko.\n",
    "\n",
    "For the context of this notebook we will use a simple 2-compartments PK model that was implemented the cookbooks project. The reference trial is available here: https://jinko.ai/tr-OJvV-CPhT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ef6139",
   "metadata": {},
   "source": [
    "## 1. Training a surrogate model\n",
    "\n",
    "### 1.1 Generate training data\n",
    "\n",
    "In order to train a surrogate model, we need to generate some data using the QSP model. Some caution needs to be taken if we want the training ot be efficient, in particular when it comes to choosing the parameter values. The most important aspect to consider here is how to choose the descriptors to include. Two questions are of importance:\n",
    "\n",
    "- What are the parameters I want to estimate the distributions of?\n",
    "- What are the parameters that will play a role in predicting the patients behavior (PDK)?\n",
    "\n",
    "This should give a good idea of the total list of parameters we want to explore in the training data set.\n",
    "\n",
    "The trial setup is important. Make sure you have loaded the right protocol design, and reasonable solving options, in particular the solving times, as the GP will be trained on each and every of the time steps included in the solving times (too many points will lead to a slow and difficult training). If the goal is to calibrate on observed data, it makes sense to filter the training set to only include the osbervation time points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1b784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT REQUIRED HERE\n",
    "# Enter your info:\n",
    "\n",
    "# the trial short id, the outputs of interest and the descriptors to be studied\n",
    "trial_sid = \"tr-OJvV-CPhT\"\n",
    "descriptors = [\"k12\", \"k21\", \"k_el\"]\n",
    "output_names = [\"A1\", \"A2\"]\n",
    "\n",
    "# A folder that will be used to dump any new project item in jinko\n",
    "folder_id = \"a1032e99-2d28-4d7d-a1b8-a9bb9eeb0c68\"\n",
    "\n",
    "# Turn this flag to true to generate a new training vpop and rerun the trial\n",
    "generate_vpop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f6edc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_project_item = jinko.get_project_item(sid=trial_sid)\n",
    "trial_core_item_id = trial_project_item[\"coreId\"][\"id\"]\n",
    "trial_snapshot_id = trial_project_item[\"coreId\"][\"snapshotId\"]\n",
    "\n",
    "# Fetching the trial content\n",
    "trial_info = jinko.make_request(\n",
    "    path=f\"/core/v2/trial_manager/trial/{trial_core_item_id}/snapshots/{trial_snapshot_id}\",\n",
    ").json()\n",
    "\n",
    "# Fetching the CM info\n",
    "model_core_item_id = trial_info[\"computationalModelId\"][\"coreItemId\"]\n",
    "model_snapshot_id = trial_info[\"computationalModelId\"][\"snapshotId\"]\n",
    "\n",
    "# Fetching the protocol design info\n",
    "protocol_design_core_id = trial_info[\"protocolDesignId\"][\"coreItemId\"]\n",
    "protocol_design_snapshot_id = trial_info[\"protocolDesignId\"][\"snapshotId\"]\n",
    "\n",
    "response = jinko.make_request(\n",
    "    path=f\"/core/v2/scenario_manager/protocol_design/{protocol_design_core_id}/snapshots/{protocol_design_snapshot_id}\",\n",
    "    method=\"GET\",\n",
    "    json={\n",
    "        \"Accept\": \"application/json;charset=utf-8, text/csv\",\n",
    "    },\n",
    ")\n",
    "protocol_design = response.json()\n",
    "protocol_arms = [arm[\"armName\"] for arm in protocol_design[\"scenarioArms\"]]\n",
    "selected_protocol_arms = protocol_arms[:3]\n",
    "print(\"selected protocol arms: \", selected_protocol_arms)\n",
    "\n",
    "# Fetching the solving times\n",
    "solving_times = trial_info[\"solvingOptions\"][\"solvingTimes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67ab15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_vpop(df):\n",
    "    vpop_descriptors = set(df.columns)\n",
    "    vpop_descriptors.remove(\"id\")\n",
    "    assert vpop_descriptors is not None\n",
    "\n",
    "    def to_patient(row):\n",
    "        return {\n",
    "            \"patientIndex\": row[\"id\"],\n",
    "            \"patientCategoricalAttributes\": [],\n",
    "            \"patientAttributes\": [\n",
    "                {\"id\": param, \"val\": row[param]} for param in vpop_descriptors\n",
    "            ],\n",
    "        }\n",
    "\n",
    "    vpop = {\"patients\": [to_patient(p) for _, p in df.iterrows()]}\n",
    "    return vpop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37000ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_vpop:\n",
    "    # Generate an exploration vpop\n",
    "    # The vpop calibration module provides a tool for that, the only thing we need is a set of parameter ranges\n",
    "    # Here we use the same range for all studied descriptors\n",
    "    ranges = {desc: {\"low\": -2.0, \"high\": 0.0, \"log\": True} for desc in descriptors}\n",
    "\n",
    "    log_nb_patients = 5\n",
    "    nb_patients = 2**log_nb_patients\n",
    "    patients = vpop_calibration.generate_vpop_from_ranges(log_nb_patients, ranges)\n",
    "\n",
    "    vpop = to_vpop(patients)\n",
    "\n",
    "    response = jinko.make_request(\n",
    "        path=\"/core/v2/vpop_manager/vpop\",\n",
    "        method=\"POST\",\n",
    "        json=vpop,\n",
    "        options={\n",
    "            \"name\": \"Training vpop for GP\",\n",
    "            \"folder_id\": folder_id,\n",
    "        },\n",
    "    )\n",
    "    vpop_item_info = jinko.get_project_item_info_from_response(response)\n",
    "    assert vpop_item_info is not None\n",
    "    vpop_core_item_id = vpop_item_info[\"coreItemId\"][\"id\"]\n",
    "    vpop_snapshot_id = vpop_item_info[\"coreItemId\"][\"snapshotId\"]\n",
    "\n",
    "    print(f\"Generated a Vpop of {nb_patients} patients, sampling {descriptors}\")\n",
    "    print(f\"Vpop link: {jinko.get_project_item_url_from_response(response)}\")\n",
    "\n",
    "    response = jinko.make_request(\n",
    "        path=f\"/core/v2/trial_manager/trial/{trial_core_item_id}/snapshots/{trial_snapshot_id}\",\n",
    "        method=\"PATCH\",\n",
    "        json={\n",
    "            \"vpopId\": {\"coreItemId\": vpop_core_item_id, \"snapshotId\": vpop_snapshot_id}\n",
    "        },\n",
    "    )\n",
    "    print(f\"Updated trial link: {jinko.get_project_item_url_from_response(response)}\")\n",
    "    new_trial_info = jinko.get_project_item_info_from_response(response)\n",
    "    assert new_trial_info is not None\n",
    "    trial_core_item_id = new_trial_info[\"coreItemId\"][\"id\"]\n",
    "    trial_snapshot_id = new_trial_info[\"coreItemId\"][\"snapshotId\"]\n",
    "\n",
    "    # Run the trial\n",
    "    response = jinko.make_request(\n",
    "        path=f\"/core/v2/trial_manager/trial/{trial_core_item_id}/snapshots/{trial_snapshot_id}/run\",\n",
    "        method=\"POST\",\n",
    "    )\n",
    "    jinko.monitor_trial_until_completion(trial_core_item_id, trial_snapshot_id)\n",
    "else:\n",
    "    # Retrieve the vpop information from jinko directly\n",
    "    vpop_core_item_id = trial_info[\"vpopId\"][\"coreItemId\"]\n",
    "    vpop_snapshot_id = trial_info[\"vpopId\"][\"snapshotId\"]\n",
    "\n",
    "    # Get the vpop content\n",
    "    response = jinko.make_request(\n",
    "        path=f\"/core/v2/vpop_manager/vpop/{vpop_core_item_id}\",\n",
    "        method=\"GET\",\n",
    "        json={\n",
    "            \"Accept\": \"application/json;charset=utf-8, text/csv\",\n",
    "        },\n",
    "    )\n",
    "    vpop_data = response.json()\n",
    "    patient_attributes_list = [\n",
    "        {\n",
    "            \"id\": p[\"patientIndex\"],\n",
    "            **{desc[\"id\"]: desc[\"val\"] for desc in p[\"patientAttributes\"]},\n",
    "        }\n",
    "        for p in vpop_data[\"patients\"]\n",
    "    ]\n",
    "    patients = pd.DataFrame(patient_attributes_list)\n",
    "    print(\"exploration vpop:\")\n",
    "    display(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a1865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve results\n",
    "timeseries_json = {\"timeseries\": {output: protocol_arms for output in output_names}}\n",
    "csvTimeSeries = \"\"\n",
    "try:\n",
    "    response = jinko.make_request(\n",
    "        path=f\"/core/v2/result_manager/trial/{trial_core_item_id}/snapshots/{trial_snapshot_id}/timeseries/download\",\n",
    "        method=\"POST\",\n",
    "        json=timeseries_json,\n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "        print(\"Time series data retrieved successfully.\")\n",
    "        archive = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "        filename = archive.namelist()[0]\n",
    "        print(f\"Extracted time series file: {filename}\")\n",
    "\n",
    "        csvTimeSeries = archive.read(filename).decode(\"utf-8\")\n",
    "\n",
    "    else:\n",
    "        print(\n",
    "            f\"Failed to retrieve time series data: {response.status_code} - {response.reason}\"\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "except Exception as e:\n",
    "    print(f\"Error during time series retrieval or processing: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0087a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge time series with patient descriptors together in a single data frame\n",
    "df_time_series = pd.read_csv(io.StringIO(csvTimeSeries))\n",
    "df_time_series = df_time_series.rename(columns={\"Patient Id\": \"id\"})\n",
    "training_df = pd.merge(df_time_series, patients, on=\"id\").rename(\n",
    "    columns={\n",
    "        \"Arm\": \"protocol_arm\",\n",
    "        \"Value\": \"value\",\n",
    "        \"Descriptor\": \"output_name\",\n",
    "        \"Time\": \"time\",\n",
    "    }\n",
    ")\n",
    "# OPTIONAL: Filter to keep only the protocol arms we want to train the GP on\n",
    "training_df = training_df.loc[training_df[\"protocol_arm\"].isin(selected_protocol_arms)]\n",
    "# Remove the training point t=0, it is not informative and brings a lot of struggle for the GP since it does not vary in the vpop\n",
    "training_df = training_df.loc[training_df[\"time\"] > 0]\n",
    "print(\"training dataframe:\")\n",
    "display(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7b196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training set quickly\n",
    "(\n",
    "    ggplot(training_df, aes(x=\"time\", y=\"value\", color=\"id\"))\n",
    "    + geom_line()\n",
    "    + facet_grid(rows=\"protocol_arm\", cols=\"output_name\")\n",
    "    + theme(legend_position=\"none\")\n",
    "    + scale_y_continuous(trans=\"log10\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305683d3",
   "metadata": {},
   "source": [
    "## 1.2 Create and train a GP model on the training data\n",
    "\n",
    "We will now instantiate a GP surrogate model and train it using the dataframe that was gathered from the jinko simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b11869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pickle = False\n",
    "override_pickle = False\n",
    "gp_file = \"gp_surrogate.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b543bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not use_pickle) or (override_pickle):\n",
    "    myGP = vpop_calibration.GP(\n",
    "        training_df,\n",
    "        descriptors + [\"time\"],\n",
    "        nb_training_iter=200,\n",
    "        nb_inducing_points=100,\n",
    "        learning_rate=0.05,\n",
    "        lr_decay=0.99,\n",
    "        min_delta=0.01,\n",
    "        log_inputs=descriptors,\n",
    "        log_outputs=output_names,\n",
    "    )\n",
    "\n",
    "    myGP.train()\n",
    "    if use_pickle and override_pickle:\n",
    "        with open(gp_file, \"wb\") as file:\n",
    "            pickle.dump(myGP, file)\n",
    "        print(f\"Model saved to {gp_file}\")\n",
    "elif use_pickle and (not override_pickle):\n",
    "    try:\n",
    "        with open(gp_file, \"rb\") as file:\n",
    "            myGP = pickle.load(file)\n",
    "\n",
    "        print(\"Model loaded successfully!\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\n",
    "            f\"File not found. Please make sure '{gp_file}' exists and is in the correct directory.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5d5771",
   "metadata": {},
   "outputs": [],
   "source": [
    "myGP.plot_obs_vs_predicted(\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0300f82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "myGP.plot_all_solutions(\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2accc481",
   "metadata": {},
   "outputs": [],
   "source": [
    "myGP.plot_individual_solution(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ea2212",
   "metadata": {},
   "source": [
    "# 2. Load the calibration data set\n",
    "\n",
    "Now that we have a surrogate model ready, we are going to be able to launch SAEM on it using some observed data.\n",
    "The things to keep in mind are the following:\n",
    "\n",
    "- observed time steps should be the same as the ones provided in the training data (adapt your training trial if necessary)\n",
    "- observed outputs should be the outputs predicted by the GP (remove unnecessary outputs from the training data)\n",
    "- observed protocols should be the same as the training protocols\n",
    "\n",
    "In the context of this tutorial, we cheat by getting some patients from the training data frame and adding noise to the observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b56c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "\n",
    "n_patients_calib = 12\n",
    "# Sample patients\n",
    "calib_patients = pd.DataFrame(\n",
    "    {\"id\": training_df.id.drop_duplicates().sample(n_patients_calib)}\n",
    ")\n",
    "# Choose one protocol arm per patient\n",
    "calib_protocols = np.array(selected_protocol_arms)[\n",
    "    rng.integers(0, len(selected_protocol_arms), n_patients_calib)\n",
    "]\n",
    "# Create a data set describing the patients (here only id and protocol arm are included, but covariates or PDK woul be included here)\n",
    "calib_patients[\"protocol_arm\"] = calib_protocols\n",
    "\n",
    "# Creat a calibration data frame\n",
    "calib_df = calib_patients.merge(training_df, on=[\"id\", \"protocol_arm\"])\n",
    "# Add proportional noise\n",
    "proportional_error = 0.1\n",
    "noise = rng.normal(1, proportional_error, calib_df.shape[0])\n",
    "calib_df.loc[:, \"value\"] = calib_df[\"value\"] * noise\n",
    "# Remove some observations at random\n",
    "calib_df = calib_df.sample(frac=0.8)\n",
    "display(calib_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51049696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the calib set quickly\n",
    "(\n",
    "    ggplot(calib_df, aes(x=\"time\", y=\"value\", color=\"id\"))\n",
    "    + geom_point()\n",
    "    + facet_grid(rows=\"protocol_arm\", cols=\"output_name\")\n",
    "    + theme(legend_position=\"none\")\n",
    "    + scale_y_continuous(trans=\"log10\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1498c984",
   "metadata": {},
   "source": [
    "# 3. Calibrate the surrogate model using SAEM\n",
    "\n",
    "In order to use SAEM, we need to define a Non-Linear Mixed Effects (NLME) model. This is the combination of a statistical model, a structural model and an error model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3390002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a structural model\n",
    "gp_structural_model = vpop_calibration.StructuralGp(myGP)\n",
    "\n",
    "# Define a parameter distribution model\n",
    "# We consider no model intrinsic parameters\n",
    "init_log_mi = {}\n",
    "# All 3 parameters are to be calibrated\n",
    "init_log_pdu = {\n",
    "    \"k12\": {\"mean\": -1.0, \"sd\": 0.5},\n",
    "    \"k21\": {\"mean\": -1.0, \"sd\": 0.5},\n",
    "    \"k_el\": {\"mean\": -1.0, \"sd\": 0.5},\n",
    "}\n",
    "# No covariates are described here\n",
    "init_covariate_map = None\n",
    "\n",
    "# Error model\n",
    "\n",
    "error_model = \"additive\"\n",
    "init_res_var = [0.05, 0.05]\n",
    "nlme_surrogate = vpop_calibration.NlmeModel(\n",
    "    gp_structural_model,\n",
    "    calib_patients,\n",
    "    init_log_mi,\n",
    "    init_log_pdu,\n",
    "    init_res_var,\n",
    "    None,\n",
    "    error_model,\n",
    ")\n",
    "\n",
    "optimizer = vpop_calibration.PySaem(\n",
    "    nlme_surrogate,\n",
    "    calib_df,\n",
    "    nb_phase1_iterations=500,\n",
    "    nb_phase2_iterations=200,\n",
    "    mcmc_nb_transitions=1,\n",
    "    verbose=False,\n",
    "    plot_frames=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5326a40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089158cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the calibrated NLME fits the observed data\n",
    "vpop_calibration.plot_map_estimates(nlme_surrogate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f59e4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings, ranges = vpop_calibration.check_surrogate_validity_gp(nlme_surrogate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ed78c9",
   "metadata": {},
   "source": [
    "# 4 Posterior validation\n",
    "\n",
    "Now that we have a calibrated NLME (surrogate) model, we can verify that the QSP model is also calibrated. A straight forward method of verifying this is to extract the maximum a posteriori (MAP) parameter estimates and generate a vpop from them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22883341",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_estimates = nlme_surrogate.map_estimates_descriptors()\n",
    "map_estimates[\"id\"] = nlme_surrogate.patients\n",
    "new_vpop = to_vpop(map_estimates)\n",
    "\n",
    "# Now you only need to push this vpop to jinko and run the model on it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
